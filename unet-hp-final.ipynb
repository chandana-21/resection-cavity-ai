{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport cv2\nfrom tqdm import tqdm_notebook, tnrange, tqdm\nfrom glob import glob\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n#Set Parameters\nIMG_HEIGHT = 256\nIMG_WIDTH = 256","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-22T06:18:46.331452Z","iopub.execute_input":"2022-10-22T06:18:46.332343Z","iopub.status.idle":"2022-10-22T06:18:53.639287Z","shell.execute_reply.started":"2022-10-22T06:18:46.332234Z","shell.execute_reply":"2022-10-22T06:18:53.638330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_org = glob(\"../input/fcm-brain-images/fcm_dataset/main/*.jpg\")\nmask_org = glob(\"../input/fcm-brain-images/fcm_dataset/mask/*.jpg\")\n\nmain_org.sort()\nmask_org.sort()\n\ntrain_files_b = main_org\nmask_files_b = mask_org","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:20:52.326183Z","iopub.execute_input":"2022-10-22T06:20:52.326646Z","iopub.status.idle":"2022-10-22T06:20:52.397651Z","shell.execute_reply.started":"2022-10-22T06:20:52.326608Z","shell.execute_reply":"2022-10-22T06:20:52.396620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gaussian Function:\ndef G(x, mean, std):\n    return np.exp(-0.5*np.square((x-mean)/std))\n\n# Membership Functions:\ndef ExtremelyDark(x, M):\n    return G(x, -50, M/6)\n\ndef VeryDark(x, M):\n    return G(x, 0, M/6)\n\ndef Dark(x, M):\n    return G(x, M/2, M/6)\n\ndef SlightlyDark(x, M):\n    return G(x, 5*M/6, M/6)\n\ndef SlightlyBright(x, M):\n    return G(x, M+(255-M)/6, (255-M)/6)\n\ndef Bright(x, M):\n    return G(x, M+(255-M)/2, (255-M)/6)\n\ndef VeryBright(x, M):\n    return G(x, 255, (255-M)/6)\n\ndef ExtremelyBright(x, M):\n    return G(x, 305, (255-M)/6)\n\n\ndef OutputFuzzySet(x, f, M, thres):\n    x = np.array(x)\n    result = f(x, M)\n    result[result > thres] = thres\n    return result\n\ndef AggregateFuzzySets(fuzzy_sets):\n    return np.max(np.stack(fuzzy_sets), axis=0)\n\ndef Infer(i, M, get_fuzzy_set=False):\n    # Calculate degree of membership for each class\n    VD = VeryDark(i, M)\n    Da = Dark(i, M)\n    SD = SlightlyDark(i, M)\n    SB = SlightlyBright(i, M)\n    Br = Bright(i, M)\n    VB = VeryBright(i, M)\n    \n    # Fuzzy Inference:\n    x = np.arange(-50, 306)\n    Inferences = (\n        OutputFuzzySet(x, ExtremelyDark, M, VD),\n        OutputFuzzySet(x, VeryDark, M, Da),\n        OutputFuzzySet(x, Dark, M, SD),\n        OutputFuzzySet(x, Bright, M, SB),\n        OutputFuzzySet(x, VeryBright, M, Br),\n        OutputFuzzySet(x, ExtremelyBright, M, VB)\n    )\n    \n    # Calculate AggregatedFuzzySet:\n    fuzzy_output = AggregateFuzzySets(Inferences)\n    \n    # Calculate crisp value of centroid\n    if get_fuzzy_set:\n        return np.average(x, weights=fuzzy_output), fuzzy_output\n    return np.average(x, weights=fuzzy_output)\n\n\n# Proposed fuzzy method\ndef FuzzyContrastEnhance(rgb):\n    # Convert RGB to LAB\n#     print(rgb)\n    lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n    \n    # Get L channel\n    l = lab[:, :, 0]\n    \n    # Calculate M value\n    M = np.mean(l)\n    if M < 128:\n        M = 127 - (127 - M)/2\n    else:\n        M = 128 + M/2\n        \n    # Precompute the fuzzy transform\n    x = list(range(-50,306))\n    FuzzyTransform = dict(zip(x,[Infer(np.array([i]), M) for i in x]))\n    \n    # Apply the transform to l channel\n    u, inv = np.unique(l, return_inverse = True)\n    l = np.array([FuzzyTransform[i] for i in u])[inv].reshape(l.shape)\n    \n    # Min-max scale the output L channel to fit (0, 255):\n    Min = np.min(l)\n    Max = np.max(l)\n    lab[:, :, 0] = (l - Min)/(Max - Min) * 255\n    \n    # Convert LAB to RGB\n    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:20:55.139160Z","iopub.execute_input":"2022-10-22T06:20:55.140348Z","iopub.status.idle":"2022-10-22T06:20:55.159535Z","shell.execute_reply.started":"2022-10-22T06:20:55.140300Z","shell.execute_reply":"2022-10-22T06:20:55.158552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"fuzzy_i\")","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:19:06.971704Z","iopub.execute_input":"2022-10-22T06:19:06.972060Z","iopub.status.idle":"2022-10-22T06:19:06.977413Z","shell.execute_reply.started":"2022-10-22T06:19:06.972030Z","shell.execute_reply":"2022-10-22T06:19:06.976021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def makeImages(train):\n    for file in tqdm(train):\n        name = file.split('/')[-1]\n#         print(name)\n        image = cv2.imread(file)\n        img = FuzzyContrastEnhance(image)\n        img = cv2.resize(img,(256,256))\n        cv2.imwrite(f'fuzzy_i/{name}', img)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:20:58.425619Z","iopub.execute_input":"2022-10-22T06:20:58.425981Z","iopub.status.idle":"2022-10-22T06:20:58.431667Z","shell.execute_reply.started":"2022-10-22T06:20:58.425951Z","shell.execute_reply":"2022-10-22T06:20:58.430672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"clahe_ii\")","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:19:13.341458Z","iopub.execute_input":"2022-10-22T06:19:13.341996Z","iopub.status.idle":"2022-10-22T06:19:13.346965Z","shell.execute_reply.started":"2022-10-22T06:19:13.341958Z","shell.execute_reply":"2022-10-22T06:19:13.345980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = makeImages(train_files_b)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:21:01.990345Z","iopub.execute_input":"2022-10-22T06:21:01.990696Z","iopub.status.idle":"2022-10-22T06:30:16.371452Z","shell.execute_reply.started":"2022-10-22T06:21:01.990667Z","shell.execute_reply":"2022-10-22T06:30:16.369945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main = glob(\"./fuzzy_i/*.jpg\")\nmain.sort()\ntrain_files_b = main","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:16.262273Z","iopub.execute_input":"2022-10-22T06:31:16.262620Z","iopub.status.idle":"2022-10-22T06:31:16.286514Z","shell.execute_reply.started":"2022-10-22T06:31:16.262591Z","shell.execute_reply":"2022-10-22T06:31:16.285651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"makeImages(train_files_b)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:04.089761Z","iopub.execute_input":"2022-09-29T10:59:04.090132Z","iopub.status.idle":"2022-09-29T10:59:30.681697Z","shell.execute_reply.started":"2022-09-29T10:59:04.090101Z","shell.execute_reply":"2022-09-29T10:59:30.680476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_cl = glob(\"./clahe_ii/*.jpg\")\nmain_cl.sort()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:09:28.073206Z","iopub.execute_input":"2022-09-29T11:09:28.073580Z","iopub.status.idle":"2022-09-29T11:09:28.098276Z","shell.execute_reply.started":"2022-09-29T11:09:28.073547Z","shell.execute_reply":"2022-09-29T11:09:28.097424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_b = pd.DataFrame(data={\"filename\": train_files_b, 'mask' : mask_files_b})\ndf_train_b, df_test_b = train_test_split(df_b,test_size = 0.1)\ndf_train_b, df_val_b = train_test_split(df_train_b,test_size = 0.2)\nprint(df_train_b.values.shape)\nprint(df_val_b.values.shape)\nprint(df_test_b.values.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:19.601980Z","iopub.execute_input":"2022-10-22T06:31:19.602747Z","iopub.status.idle":"2022-10-22T06:31:19.624067Z","shell.execute_reply.started":"2022-10-22T06:31:19.602701Z","shell.execute_reply":"2022-10-22T06:31:19.623054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n    '''\n    can generate image and mask at the same time use the same seed for\n    image_datagen and mask_datagen to ensure the transformation for image\n    and mask is the same if you want to visualize the results of generator,\n    set save_to_dir = \"your path\"\n    '''\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img / 255\n    mask = mask / 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:22.699887Z","iopub.execute_input":"2022-10-22T06:31:22.700269Z","iopub.status.idle":"2022-10-22T06:31:22.711488Z","shell.execute_reply.started":"2022-10-22T06:31:22.700227Z","shell.execute_reply":"2022-10-22T06:31:22.710430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smooth = 1\n\ndef dice_coef(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    And=K.sum(y_truef* y_predf)\n    return((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n\n    return - iou(y_true, y_pred)\n\nimport keras.backend as K\n\ndef get_f1(y_true, y_pred): \n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0.0, 1.0)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0.0, 1.0)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:24.418674Z","iopub.execute_input":"2022-10-22T06:31:24.419023Z","iopub.status.idle":"2022-10-22T06:31:24.431285Z","shell.execute_reply.started":"2022-10-22T06:31:24.418992Z","shell.execute_reply":"2022-10-22T06:31:24.430383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU\nfrom tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Concatenate\nfrom tensorflow.keras.models import Model, Sequential","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:32:34.339864Z","iopub.execute_input":"2022-10-22T06:32:34.340275Z","iopub.status.idle":"2022-10-22T06:32:34.346168Z","shell.execute_reply.started":"2022-10-22T06:32:34.340224Z","shell.execute_reply":"2022-10-22T06:32:34.344925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:27.915655Z","iopub.execute_input":"2022-10-22T06:31:27.916017Z","iopub.status.idle":"2022-10-22T06:31:27.920339Z","shell.execute_reply.started":"2022-10-22T06:31:27.915984Z","shell.execute_reply":"2022-10-22T06:31:27.919333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c__i = cv2.imread(main_cl[181])","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:09:34.082341Z","iopub.execute_input":"2022-09-29T11:09:34.083048Z","iopub.status.idle":"2022-09-29T11:09:34.088506Z","shell.execute_reply.started":"2022-09-29T11:09:34.083011Z","shell.execute_reply":"2022-09-29T11:09:34.087295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f__i = cv2.imread(train_files_b[181])","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:06:39.057192Z","iopub.execute_input":"2022-09-29T11:06:39.057912Z","iopub.status.idle":"2022-09-29T11:06:39.063489Z","shell.execute_reply.started":"2022-09-29T11:06:39.057877Z","shell.execute_reply":"2022-09-29T11:06:39.062346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def MSE(img1, img2):\n    return np.mean(np.square(img1 - img2))\n\ndef PSNR(Max, MSE):\n    return 10*math.log10(Max**2/MSE)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:31.476857Z","iopub.execute_input":"2022-10-22T06:31:31.477233Z","iopub.status.idle":"2022-10-22T06:31:31.482565Z","shell.execute_reply.started":"2022-10-22T06:31:31.477179Z","shell.execute_reply":"2022-10-22T06:31:31.481551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, Markdown","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:35.975561Z","iopub.execute_input":"2022-10-22T06:31:35.975935Z","iopub.status.idle":"2022-10-22T06:31:35.980579Z","shell.execute_reply.started":"2022-10-22T06:31:35.975904Z","shell.execute_reply":"2022-10-22T06:31:35.979464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:08:02.617178Z","iopub.execute_input":"2022-09-29T11:08:02.617559Z","iopub.status.idle":"2022-09-29T11:08:02.622189Z","shell.execute_reply.started":"2022-09-29T11:08:02.617529Z","shell.execute_reply":"2022-09-29T11:08:02.621100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m_org = cv2.imread(main_org[181])\nm_org = cv2.resize(m_org,(256,256))\n\n\ndisplay(Markdown(f'FCE: {PSNR(255*255, np.mean([MSE(m_org, f__i ) ]))}'))\n\ndisplay(Markdown(f'CLAHE: {PSNR(255*255, np.mean([MSE(m_org,  c__i) ]))}'))","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:09:36.387341Z","iopub.execute_input":"2022-09-29T11:09:36.388456Z","iopub.status.idle":"2022-09-29T11:09:36.405536Z","shell.execute_reply.started":"2022-09-29T11:09:36.388385Z","shell.execute_reply":"2022-09-29T11:09:36.404693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convolution_operation(entered_input, filters=64):\n    # Taking first input and implementing the first conv block\n    conv1 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(entered_input)\n    batch_norm1 = BatchNormalization()(conv1)\n    act1 = Activation('relu')(batch_norm1)\n    \n    # Taking first input and implementing the second conv block\n    conv2 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(act1)\n    batch_norm2 = BatchNormalization()(conv2)\n    act2 = Activation('relu')(batch_norm2)\n    \n    return act2\n\n\ndef encoder(entered_input, filters=64):\n    # Collect the start and end of each sub-block for normal pass and skip connections\n    enc1 = convolution_operation(entered_input, filters)\n    MaxPool1 = MaxPooling2D(strides = (2,2))(enc1)\n    return enc1, MaxPool1\n\ndef decoder(entered_input, skip, filters=64):\n    # Upsampling and concatenating the essential features\n    Upsample = Conv2DTranspose(filters, (2, 2), strides=2, padding=\"same\")(entered_input)\n    Connect_Skip = Concatenate()([Upsample, skip])\n    out = convolution_operation(Connect_Skip, filters)\n    return out\n\ndef U_Net(Image_Size):\n    # Take the image size and shape\n    input1 = Input(Image_Size)\n    \n    # Construct the encoder blocks\n    skip1, encoder_1 = encoder(input1, 64)\n    skip2, encoder_2 = encoder(encoder_1, 64*2)\n    skip3, encoder_3 = encoder(encoder_2, 64*4)\n    skip4, encoder_4 = encoder(encoder_3, 64*8)\n    \n    # Preparing the next block\n    conv_block_1 = convolution_operation(encoder_4, 64*16)\n    \n    # Construct the decoder blocks\n    decoder_1 = decoder(conv_block_1, skip4, 64*8)\n    decoder_2 = decoder(decoder_1, skip3, 64*4)\n    decoder_3 = decoder(decoder_2, skip2, 64*2)\n    decoder_4 = decoder(decoder_3, skip1, 64)\n    \n    out = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(decoder_4)\n\n    model = Model(input1, out)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:35:43.388250Z","iopub.execute_input":"2022-10-22T06:35:43.388995Z","iopub.status.idle":"2022-10-22T06:35:43.405668Z","shell.execute_reply.started":"2022-10-22T06:35:43.388950Z","shell.execute_reply":"2022-10-22T06:35:43.404385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 25 # 40\nBATCH_SIZE = 32\nlearning_rate = 1e-4","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:43.639297Z","iopub.execute_input":"2022-10-22T06:31:43.639646Z","iopub.status.idle":"2022-10-22T06:31:43.644944Z","shell.execute_reply.started":"2022-10-22T06:31:43.639616Z","shell.execute_reply":"2022-10-22T06:31:43.643849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.09,\n                            height_shift_range=0.09,\n                            shear_range=0.09,\n                            zoom_range=0.09,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train_b, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=(256, 256))\n    \ntest_gener = train_generator(df_val_b, BATCH_SIZE,\n                                dict(),\n                                target_size=(256, 256))","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:31:51.673100Z","iopub.execute_input":"2022-10-22T06:31:51.673680Z","iopub.status.idle":"2022-10-22T06:31:51.679598Z","shell.execute_reply.started":"2022-10-22T06:31:51.673646Z","shell.execute_reply":"2022-10-22T06:31:51.678660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (256, 256, 3)\n\nmodel = U_Net(input_shape)\n# model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n\ndecay_rate = learning_rate / EPOCHS\nopt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\nmodel.compile(optimizer=opt, loss=dice_coef_loss, metrics=[\"binary_accuracy\", iou, dice_coef, get_f1])\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:35:46.880896Z","iopub.execute_input":"2022-10-22T06:35:46.881274Z","iopub.status.idle":"2022-10-22T06:35:47.291581Z","shell.execute_reply.started":"2022-10-22T06:35:46.881241Z","shell.execute_reply":"2022-10-22T06:35:47.290428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ModelCheckpoint('fuzzy_e.hdf5', verbose=1, save_best_only=True), tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train_b) / BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                   validation_data=test_gener,\n                   validation_steps = len(df_val_b) / BATCH_SIZE) ","metadata":{"execution":{"iopub.status.busy":"2022-10-22T06:35:52.642453Z","iopub.execute_input":"2022-10-22T06:35:52.642816Z","iopub.status.idle":"2022-10-22T07:32:29.042372Z","shell.execute_reply.started":"2022-10-22T06:35:52.642787Z","shell.execute_reply":"2022-10-22T07:32:29.041328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = history.history\n\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nlist_trainjaccard = a['iou']\nlist_testjaccard = a['val_iou']\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\nplt.figure(1)\nplt.plot(list_testloss, 'b-')\nplt.plot(list_trainloss,'r-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(list_traindice, 'r-')\nplt.plot(list_testdice, 'b-')\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.title('accuracy graph', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T12:16:16.204130Z","iopub.execute_input":"2022-09-29T12:16:16.204527Z","iopub.status.idle":"2022-09-29T12:16:16.583228Z","shell.execute_reply.started":"2022-09-29T12:16:16.204494Z","shell.execute_reply":"2022-09-29T12:16:16.582347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = load_model('unet_brain.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = train_generator(df_test_b, BATCH_SIZE,\n                                dict(),\n                                target_size=(256, 256))\nresults = model.evaluate(test_gen, steps=len(df_test_b) / BATCH_SIZE)\nprint(\"Test loss: \",results[0])\nprint(\"Binary Accuracy: \",results[1])\nprint(\"Test IOU: \",results[2])\nprint(\"Test Dice Coefficent: \",results[3])\nprint(\"F1 score: \",results[4])","metadata":{"execution":{"iopub.status.busy":"2022-10-22T07:37:07.384692Z","iopub.execute_input":"2022-10-22T07:37:07.385090Z","iopub.status.idle":"2022-10-22T07:37:17.382196Z","shell.execute_reply.started":"2022-10-22T07:37:07.385052Z","shell.execute_reply":"2022-10-22T07:37:17.380823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = train_generator(df_test_b, BATCH_SIZE,\n                                dict(),\n                                target_size=(256, 256))\nresults = model.evaluate(test_gen, steps=len(df_test_b) / BATCH_SIZE)\nprint(\"Test loss: \",results[0])\nprint(\"Binary Accuracy: \",results[1])\nprint(\"Test IOU: \",results[2])\nprint(\"Test Dice Coefficent: \",results[3])\nprint(\"F1 score: \",results[4])","metadata":{"execution":{"iopub.status.busy":"2022-09-29T12:16:26.032207Z","iopub.execute_input":"2022-09-29T12:16:26.032892Z","iopub.status.idle":"2022-09-29T12:16:31.645380Z","shell.execute_reply.started":"2022-09-29T12:16:26.032854Z","shell.execute_reply":"2022-09-29T12:16:31.644113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_height, im_width = 256,256","metadata":{"execution":{"iopub.status.busy":"2022-10-22T07:38:47.954813Z","iopub.execute_input":"2022-10-22T07:38:47.955165Z","iopub.status.idle":"2022-10-22T07:38:47.960744Z","shell.execute_reply.started":"2022-10-22T07:38:47.955135Z","shell.execute_reply":"2022-10-22T07:38:47.959777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test_b.index))\n    print(index)\n    img = cv2.imread(df_test_b['filename'].iloc[index])\n    img = cv2.resize(img ,(im_height, im_width))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test_b['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-22T07:38:48.297424Z","iopub.execute_input":"2022-10-22T07:38:48.299496Z","iopub.status.idle":"2022-10-22T07:39:03.279014Z","shell.execute_reply.started":"2022-10-22T07:38:48.299466Z","shell.execute_reply":"2022-10-22T07:39:03.278096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test_b.index))\n    print(index)\n    img = cv2.imread(df_test_b['filename'].iloc[index])\n    img = cv2.resize(img ,(im_height, im_width))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test_b['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T12:19:08.946827Z","iopub.execute_input":"2022-09-29T12:19:08.947198Z","iopub.status.idle":"2022-09-29T12:19:23.212086Z","shell.execute_reply.started":"2022-09-29T12:19:08.947166Z","shell.execute_reply":"2022-09-29T12:19:23.211147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test_b.index))\n    print(index)\n    img = cv2.imread(df_test_b['filename'].iloc[index])\n    img = cv2.resize(img ,(im_height, im_width))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test_b['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T12:19:32.651781Z","iopub.execute_input":"2022-09-29T12:19:32.652136Z","iopub.status.idle":"2022-09-29T12:19:46.674258Z","shell.execute_reply.started":"2022-09-29T12:19:32.652105Z","shell.execute_reply":"2022-09-29T12:19:46.673265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport cv2\nfrom tqdm import tqdm_notebook, tnrange, tqdm\nfrom glob import glob\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n#Set Parameters\nIMG_HEIGHT = 256\nIMG_WIDTH = 256","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-22T09:31:24.343604Z","iopub.execute_input":"2022-10-22T09:31:24.344046Z","iopub.status.idle":"2022-10-22T09:31:30.212894Z","shell.execute_reply.started":"2022-10-22T09:31:24.343960Z","shell.execute_reply":"2022-10-22T09:31:30.211941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main = glob(\"../input/fcm-brain-images/fcm_dataset/main/*.jpg\")\nmask = glob(\"../input/fcm-brain-images/fcm_dataset/mask/*.jpg\")\n\nmain.sort()\nmask.sort()\n\ntrain_files_b = main\nmask_files_b = mask","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:31:30.214744Z","iopub.execute_input":"2022-10-22T09:31:30.215408Z","iopub.status.idle":"2022-10-22T09:31:30.879502Z","shell.execute_reply.started":"2022-10-22T09:31:30.215371Z","shell.execute_reply":"2022-10-22T09:31:30.878555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tempo = train_files_b[181]\ni = cv2.imread(tempo)\nx = FuzzyContrastEnhance(i)\nplt.figure(figsize=(10,10))\nplt.grid(False)\nplt.imshow(x)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T16:35:26.012212Z","iopub.execute_input":"2022-09-30T16:35:26.012658Z","iopub.status.idle":"2022-09-30T16:35:26.419065Z","shell.execute_reply.started":"2022-09-30T16:35:26.012617Z","shell.execute_reply":"2022-09-30T16:35:26.418136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc = CLAHE(i)\nplt.figure(figsize=(10,10))\nplt.grid(False)\nplt.imshow(cc)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T16:35:32.133627Z","iopub.execute_input":"2022-09-30T16:35:32.133987Z","iopub.status.idle":"2022-09-30T16:35:32.495690Z","shell.execute_reply.started":"2022-09-30T16:35:32.133955Z","shell.execute_reply":"2022-09-30T16:35:32.492608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newww = CLAHE(x)\nplt.figure(figsize=(10,10))\nplt.grid(False)\nplt.imshow(newww)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T16:35:37.334892Z","iopub.execute_input":"2022-09-30T16:35:37.335278Z","iopub.status.idle":"2022-09-30T16:35:37.665027Z","shell.execute_reply.started":"2022-09-30T16:35:37.335244Z","shell.execute_reply":"2022-09-30T16:35:37.664147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lll = FuzzyContrastEnhance(cc)\nplt.figure(figsize=(10,10))\nplt.grid(False)\nplt.imshow(lll)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T16:35:42.142509Z","iopub.execute_input":"2022-09-30T16:35:42.142857Z","iopub.status.idle":"2022-09-30T16:35:42.584582Z","shell.execute_reply.started":"2022-09-30T16:35:42.142827Z","shell.execute_reply":"2022-09-30T16:35:42.581498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# m_org = cv2.imread(main_org[181])\n# m_org = cv2.resize(i,(256,256))\n\n\ndisplay(Markdown(f'FCE: {PSNR(255*255, np.mean([MSE(i, x ) ]))}'))\n\ndisplay(Markdown(f'CLAHE: {PSNR(255*255, np.mean([MSE(i,  cc) ]))}'))\n\ndisplay(Markdown(f'CLAHE (fuzzy): {PSNR(255*255, np.mean([MSE(i,  newww) ]))}'))\n\ndisplay(Markdown(f'fuzzy (CLAHE) : {PSNR(255*255, np.mean([MSE(i,  lll) ]))}'))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-30T15:54:18.377456Z","iopub.execute_input":"2022-09-30T15:54:18.378121Z","iopub.status.idle":"2022-09-30T15:54:18.394985Z","shell.execute_reply.started":"2022-09-30T15:54:18.378061Z","shell.execute_reply":"2022-09-30T15:54:18.393795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gaussian Function:\ndef G(x, mean, std):\n    return np.exp(-0.5*np.square((x-mean)/std))\n\n# Membership Functions:\n# def ExtremelyDark(x, M):\n#     return G(x, 0, M/6)\n\n# def VeryDark(x, M):\n#     return G(x, M/10, M/4)\n\n# def Dark(x, M):\n#     return G(x, M/2, M/6)\n\n# def SlightlyDark(x, M):\n#     return G(x, 5*M/6, M/6)\n\ndef ExtremelyDark(x, M):\n    return G(x, -10, M/6)\n\ndef VeryDark(x, M):\n    return G(x, 0, M/6)\n\ndef Dark(x, M):\n    return G(x, M/2, M/6)\n\ndef SlightlyDark(x, M):\n    return G(x, 5*M/6, M/6)\n\ndef SlightlyBright(x, M):\n    return G(x, M+(255-M)/6, (255-M)/6)\n\ndef Bright(x, M):\n    return G(x, M+(255-M)/2, (255-M)/6)\n\ndef VeryBright(x, M):\n    return G(x, 255, (255-M)/6)\n\ndef ExtremelyBright(x, M):\n    return G(x, 305, (255-M)/6)\n\n\ndef OutputFuzzySet(x, f, M, thres):\n    x = np.array(x)\n    result = f(x, M)\n    result[result > thres] = thres\n    return result\n\ndef AggregateFuzzySets(fuzzy_sets):\n    return np.max(np.stack(fuzzy_sets), axis=0)\n\ndef Infer(i, M, get_fuzzy_set=False):\n    # Calculate degree of membership for each class\n    VD = VeryDark(i, M)\n    Da = Dark(i, M)\n    SD = SlightlyDark(i, M)\n    SB = SlightlyBright(i, M)\n    Br = Bright(i, M)\n    VB = VeryBright(i, M)\n    \n    # Fuzzy Inference:\n    x = np.arange(-50, 306)\n    Inferences = (\n        OutputFuzzySet(x, ExtremelyDark, M, VD),\n        OutputFuzzySet(x, VeryDark, M, Da),\n        OutputFuzzySet(x, Dark, M, SD),\n        OutputFuzzySet(x, Bright, M, SB),\n        OutputFuzzySet(x, VeryBright, M, Br),\n        OutputFuzzySet(x, ExtremelyBright, M, VB)\n    )\n    \n    # Calculate AggregatedFuzzySet:\n    fuzzy_output = AggregateFuzzySets(Inferences)\n    \n    # Calculate crisp value of centroid\n    if get_fuzzy_set:\n        return np.average(x, weights=fuzzy_output), fuzzy_output\n    return np.average(x, weights=fuzzy_output)\n\n\n# Proposed fuzzy method\ndef FuzzyContrastEnhance(rgb):\n    # Convert RGB to LAB\n#     print(rgb)\n    lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n    \n    # Get L channel\n    l = lab[:, :, 0]\n    \n    # Calculate M value\n    M = np.mean(l)\n    if M < 128:\n        M = 127 - (127 - M)/2\n    else:\n        M = 128 + M/2\n        \n    # Precompute the fuzzy transform\n    x = list(range(-50,306))\n    FuzzyTransform = dict(zip(x,[Infer(np.array([i]), M) for i in x]))\n    \n    # Apply the transform to l channel\n    u, inv = np.unique(l, return_inverse = True)\n    l = np.array([FuzzyTransform[i] for i in u])[inv].reshape(l.shape)\n    \n    # Min-max scale the output L channel to fit (0, 255):\n    Min = np.min(l)\n    Max = np.max(l)\n    lab[:, :, 0] = (l - Min)/(Max - Min) * 255\n    \n    # Convert LAB to RGB\n    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:31:32.571609Z","iopub.execute_input":"2022-10-22T09:31:32.572686Z","iopub.status.idle":"2022-10-22T09:31:32.590898Z","shell.execute_reply.started":"2022-10-22T09:31:32.572637Z","shell.execute_reply":"2022-10-22T09:31:32.589635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"fuzzy_i\")","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:31:34.578287Z","iopub.execute_input":"2022-10-22T09:31:34.578655Z","iopub.status.idle":"2022-10-22T09:31:34.583001Z","shell.execute_reply.started":"2022-10-22T09:31:34.578622Z","shell.execute_reply":"2022-10-22T09:31:34.582091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def makeImages(train):\n    for file in tqdm(train):\n        name = file.split('/')[-1]\n#         print(name)\n        image = cv2.imread(file)\n        img = FuzzyContrastEnhance(image)\n        img = cv2.resize(img,(256,256))\n        cv2.imwrite(f'fuzzy_i/{name}', img)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:31:35.042927Z","iopub.execute_input":"2022-10-22T09:31:35.043309Z","iopub.status.idle":"2022-10-22T09:31:35.050107Z","shell.execute_reply.started":"2022-10-22T09:31:35.043278Z","shell.execute_reply":"2022-10-22T09:31:35.048972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CLAHE(image):\n#     image = cv2.imread(filename)\n    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(8, 8))\n    image[:,:,0] = clahe.apply(image[:,:,0])\n    image[:,:,1] = clahe.apply(image[:,:,1])\n    image[:,:,2] = clahe.apply(image[:,:,2])\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-09-30T15:49:05.200749Z","iopub.execute_input":"2022-09-30T15:49:05.201214Z","iopub.status.idle":"2022-09-30T15:49:05.210391Z","shell.execute_reply.started":"2022-09-30T15:49:05.201170Z","shell.execute_reply":"2022-09-30T15:49:05.208402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.mkdir(\"clahe_ii\")","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:58:27.456629Z","iopub.execute_input":"2022-09-29T10:58:27.457014Z","iopub.status.idle":"2022-09-29T10:58:27.464533Z","shell.execute_reply.started":"2022-09-29T10:58:27.456983Z","shell.execute_reply":"2022-09-29T10:58:27.463418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def makeImages(train):\n#     for file in tqdm(train):\n#         name = file.split('/')[-1]\n#         img = CLAHE(file)\n#         img = cv2.resize(img,(256,256))\n#         cv2.imwrite(f'clahe_ii/{name}', img)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:58:32.412591Z","iopub.execute_input":"2022-09-29T10:58:32.412944Z","iopub.status.idle":"2022-09-29T10:58:32.419270Z","shell.execute_reply.started":"2022-09-29T10:58:32.412914Z","shell.execute_reply":"2022-09-29T10:58:32.418132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = makeImages(train_files_b)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:31:40.048887Z","iopub.execute_input":"2022-10-22T09:31:40.049240Z","iopub.status.idle":"2022-10-22T09:40:33.295385Z","shell.execute_reply.started":"2022-10-22T09:31:40.049211Z","shell.execute_reply":"2022-10-22T09:40:33.294366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main = glob(\"./fuzzy_i/*.jpg\")\nmain.sort()\ntrain_files_b = main","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.297255Z","iopub.execute_input":"2022-10-22T09:40:33.298042Z","iopub.status.idle":"2022-10-22T09:40:33.322212Z","shell.execute_reply.started":"2022-10-22T09:40:33.298003Z","shell.execute_reply":"2022-10-22T09:40:33.321364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# makeImages(train_files_b)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:04.089761Z","iopub.execute_input":"2022-09-29T10:59:04.090132Z","iopub.status.idle":"2022-09-29T10:59:30.681697Z","shell.execute_reply.started":"2022-09-29T10:59:04.090101Z","shell.execute_reply":"2022-09-29T10:59:30.680476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# main_cl = glob(\"./clahe_ii/*.jpg\")\n# main_cl.sort()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:09:28.073206Z","iopub.execute_input":"2022-09-29T11:09:28.073580Z","iopub.status.idle":"2022-09-29T11:09:28.098276Z","shell.execute_reply.started":"2022-09-29T11:09:28.073547Z","shell.execute_reply":"2022-09-29T11:09:28.097424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_b = pd.DataFrame(data={\"filename\": train_files_b, 'mask' : mask_files_b})\ndf_train_b, df_test_b = train_test_split(df_b,test_size = 0.1)\ndf_train_b, df_val_b = train_test_split(df_train_b,test_size = 0.2)\nprint(df_train_b.values.shape)\nprint(df_val_b.values.shape)\nprint(df_test_b.values.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.323607Z","iopub.execute_input":"2022-10-22T09:40:33.324215Z","iopub.status.idle":"2022-10-22T09:40:33.339875Z","shell.execute_reply.started":"2022-10-22T09:40:33.324180Z","shell.execute_reply":"2022-10-22T09:40:33.338797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=21):\n    '''\n    can generate image and mask at the same time use the same seed for\n    image_datagen and mask_datagen to ensure the transformation for image\n    and mask is the same if you want to visualize the results of generator,\n    set save_to_dir = \"your path\"\n    '''\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img / 255\n    mask = mask / 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.343129Z","iopub.execute_input":"2022-10-22T09:40:33.343678Z","iopub.status.idle":"2022-10-22T09:40:33.354705Z","shell.execute_reply.started":"2022-10-22T09:40:33.343643Z","shell.execute_reply":"2022-10-22T09:40:33.353790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smooth = 1\n\ndef dice_coef(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    And=K.sum(y_truef* y_predf)\n    return((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n\n    return - iou(y_true, y_pred)\n\nimport keras.backend as K\n\ndef get_f1(y_true, y_pred): \n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0.0, 1.0)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0.0, 1.0)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.356396Z","iopub.execute_input":"2022-10-22T09:40:33.356814Z","iopub.status.idle":"2022-10-22T09:40:33.367645Z","shell.execute_reply.started":"2022-10-22T09:40:33.356718Z","shell.execute_reply":"2022-10-22T09:40:33.366652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU\nfrom tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Concatenate\nfrom tensorflow.keras.models import Model, Sequential","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.369178Z","iopub.execute_input":"2022-10-22T09:40:33.369781Z","iopub.status.idle":"2022-10-22T09:40:33.378675Z","shell.execute_reply.started":"2022-10-22T09:40:33.369720Z","shell.execute_reply":"2022-10-22T09:40:33.377664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:08.332643Z","iopub.execute_input":"2022-09-29T10:54:08.333667Z","iopub.status.idle":"2022-09-29T10:54:08.338739Z","shell.execute_reply.started":"2022-09-29T10:54:08.333617Z","shell.execute_reply":"2022-09-29T10:54:08.337540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c__i = cv2.imread(main_cl[181])","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:09:34.082341Z","iopub.execute_input":"2022-09-29T11:09:34.083048Z","iopub.status.idle":"2022-09-29T11:09:34.088506Z","shell.execute_reply.started":"2022-09-29T11:09:34.083011Z","shell.execute_reply":"2022-09-29T11:09:34.087295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f__i = cv2.imread(train_files_b[181])","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:06:39.057192Z","iopub.execute_input":"2022-09-29T11:06:39.057912Z","iopub.status.idle":"2022-09-29T11:06:39.063489Z","shell.execute_reply.started":"2022-09-29T11:06:39.057877Z","shell.execute_reply":"2022-09-29T11:06:39.062346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def MSE(img1, img2):\n    return np.mean(np.square(img1 - img2))\n\ndef PSNR(Max, MSE):\n    return 10*math.log10(Max**2/MSE)","metadata":{"execution":{"iopub.status.busy":"2022-09-30T14:27:16.645438Z","iopub.execute_input":"2022-09-30T14:27:16.645790Z","iopub.status.idle":"2022-09-30T14:27:16.650745Z","shell.execute_reply.started":"2022-09-30T14:27:16.645760Z","shell.execute_reply":"2022-09-30T14:27:16.649794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, Markdown","metadata":{"execution":{"iopub.status.busy":"2022-09-30T14:24:54.655518Z","iopub.execute_input":"2022-09-30T14:24:54.655886Z","iopub.status.idle":"2022-09-30T14:24:54.661341Z","shell.execute_reply.started":"2022-09-30T14:24:54.655855Z","shell.execute_reply":"2022-09-30T14:24:54.660246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math","metadata":{"execution":{"iopub.status.busy":"2022-09-30T14:24:54.999969Z","iopub.execute_input":"2022-09-30T14:24:55.000330Z","iopub.status.idle":"2022-09-30T14:24:55.004585Z","shell.execute_reply.started":"2022-09-30T14:24:55.000298Z","shell.execute_reply":"2022-09-30T14:24:55.003488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convolution_operation(entered_input, filters=64):\n    # Taking first input and implementing the first conv block\n    conv1 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(entered_input)\n    batch_norm1 = BatchNormalization()(conv1)\n    act1 = Activation('relu')(batch_norm1)\n    \n    # Taking first input and implementing the second conv block\n    conv2 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(act1)\n    batch_norm2 = BatchNormalization()(conv2)\n    act2 = Activation('relu')(batch_norm2)\n    return act2\n\n\ndef encoder(entered_input, filters=64):\n    # Collect the start and end of each sub-block for normal pass and skip connections\n    enc1 = convolution_operation(entered_input, filters)\n    MaxPool1 = MaxPooling2D(strides = (2,2))(enc1)\n    return enc1, MaxPool1\n\ndef decoder(entered_input, skip, filters=64):\n    # Upsampling and concatenating the essential features\n    Upsample = Conv2DTranspose(filters, (2, 2), strides=2, padding=\"same\")(entered_input)\n    Connect_Skip = Concatenate()([Upsample, skip])\n    out = convolution_operation(Connect_Skip, filters)\n    return out\n\ndef U_Net(Image_Size):\n    # Take the image size and shape\n    input1 = Input(Image_Size)\n    \n    # Construct the encoder blocks\n    skip1, encoder_1 = encoder(input1, 64)\n    skip2, encoder_2 = encoder(encoder_1, 64*2)\n    skip3, encoder_3 = encoder(encoder_2, 64*4)\n    skip4, encoder_4 = encoder(encoder_3, 64*8)\n    \n    # Preparing the next block\n    conv_block = convolution_operation(encoder_4, 64*16)\n    \n    # Construct the decoder blocks\n    decoder_1 = decoder(conv_block, skip4, 64*8)\n    decoder_2 = decoder(decoder_1, skip3, 64*4)\n    decoder_3 = decoder(decoder_2, skip2, 64*2)\n    decoder_4 = decoder(decoder_3, skip1, 64)\n    \n    out = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(decoder_4)\n\n    model = Model(input1, out)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.380845Z","iopub.execute_input":"2022-10-22T09:40:33.381159Z","iopub.status.idle":"2022-10-22T09:40:33.393713Z","shell.execute_reply.started":"2022-10-22T09:40:33.381134Z","shell.execute_reply":"2022-10-22T09:40:33.392661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 25 # 40\nBATCH_SIZE = 32\nlearning_rate = 1e-4","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.395249Z","iopub.execute_input":"2022-10-22T09:40:33.396194Z","iopub.status.idle":"2022-10-22T09:40:33.403879Z","shell.execute_reply.started":"2022-10-22T09:40:33.396141Z","shell.execute_reply":"2022-10-22T09:40:33.402980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.09,\n                            height_shift_range=0.09,\n                            shear_range=0.09,\n                            zoom_range=0.09,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\n\ntrain_gen = train_generator(df_train_b, BATCH_SIZE,\n                                train_generator_args,\n#                                  dict(),\n                                target_size=(256, 256))\n    \ntest_gener = train_generator(df_val_b, BATCH_SIZE,\n                                dict(),\n                                \n                                target_size=(256, 256))","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.405549Z","iopub.execute_input":"2022-10-22T09:40:33.406002Z","iopub.status.idle":"2022-10-22T09:40:33.412914Z","shell.execute_reply.started":"2022-10-22T09:40:33.405969Z","shell.execute_reply":"2022-10-22T09:40:33.411936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (256, 256, 3)\n\nmodel = U_Net(input_shape)\n# model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n\ndecay_rate = learning_rate / EPOCHS\nopt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\nmodel.compile(optimizer=opt, loss=dice_coef_loss, metrics=[\"binary_accuracy\", iou, dice_coef, get_f1])\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:33.415873Z","iopub.execute_input":"2022-10-22T09:40:33.416613Z","iopub.status.idle":"2022-10-22T09:40:36.498682Z","shell.execute_reply.started":"2022-10-22T09:40:33.416578Z","shell.execute_reply":"2022-10-22T09:40:36.497732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ModelCheckpoint('fuzzy.hdf5', verbose=1, save_best_only=True)]\n\n# , tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train_b) / BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                   validation_data=test_gener,\n                   validation_steps = len(df_val_b) / BATCH_SIZE) ","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:40:36.499942Z","iopub.execute_input":"2022-10-22T09:40:36.500274Z","iopub.status.idle":"2022-10-22T10:37:11.905427Z","shell.execute_reply.started":"2022-10-22T09:40:36.500243Z","shell.execute_reply":"2022-10-22T10:37:11.904272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = history.history\n\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nlist_trainjaccard = a['iou']\nlist_testjaccard = a['val_iou']\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\nplt.figure(1)\nplt.plot(list_testloss, 'b-')\nplt.plot(list_trainloss,'r-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(list_traindice, 'r-')\nplt.plot(list_testdice, 'b-')\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.title('accuracy graph', fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T15:39:17.586070Z","iopub.execute_input":"2022-09-30T15:39:17.586781Z","iopub.status.idle":"2022-09-30T15:39:17.949949Z","shell.execute_reply.started":"2022-09-30T15:39:17.586743Z","shell.execute_reply":"2022-09-30T15:39:17.949000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('./fuzzy.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef, 'get_f1':get_f1})","metadata":{"execution":{"iopub.status.busy":"2022-09-30T17:56:07.032070Z","iopub.execute_input":"2022-09-30T17:56:07.032776Z","iopub.status.idle":"2022-09-30T17:56:07.648723Z","shell.execute_reply.started":"2022-09-30T17:56:07.032740Z","shell.execute_reply":"2022-09-30T17:56:07.647620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = train_generator(df_test_b, BATCH_SIZE,\n                                dict(),\n                                target_size=(256, 256))\nresults = model.evaluate(test_gen, steps=len(df_test_b) / BATCH_SIZE)\nprint(\"Test loss: \",results[0])\nprint(\"Binary Accuracy: \",results[1])\nprint(\"Test IOU: \",results[2])\nprint(\"Test Dice Coefficent: \",results[3])\nprint(\"F1 score: \",results[4])","metadata":{"execution":{"iopub.status.busy":"2022-10-22T10:37:43.103431Z","iopub.execute_input":"2022-10-22T10:37:43.105050Z","iopub.status.idle":"2022-10-22T10:37:48.647838Z","shell.execute_reply.started":"2022-10-22T10:37:43.105006Z","shell.execute_reply":"2022-10-22T10:37:48.646884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = train_generator(df_test_b, BATCH_SIZE,\n                                dict(),\n                                target_size=(256, 256))\nresults = model.evaluate(test_gen, steps=len(df_test_b) / BATCH_SIZE)\nprint(\"Test loss: \",results[0])\nprint(\"Binary Accuracy: \",results[1])\nprint(\"Test IOU: \",results[2])\nprint(\"Test Dice Coefficent: \",results[3])\nprint(\"F1 score: \",results[4])","metadata":{"execution":{"iopub.status.busy":"2022-09-29T12:16:26.032207Z","iopub.execute_input":"2022-09-29T12:16:26.032892Z","iopub.status.idle":"2022-09-29T12:16:31.645380Z","shell.execute_reply.started":"2022-09-29T12:16:26.032854Z","shell.execute_reply":"2022-09-29T12:16:31.644113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_height, im_width = 256,256","metadata":{"execution":{"iopub.status.busy":"2022-09-30T17:51:41.532438Z","iopub.execute_input":"2022-09-30T17:51:41.532797Z","iopub.status.idle":"2022-09-30T17:51:41.539267Z","shell.execute_reply.started":"2022-09-30T17:51:41.532767Z","shell.execute_reply":"2022-09-30T17:51:41.538139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test_b.index))\n    print(index)\n    img = cv2.imread(df_test_b['filename'].iloc[index])\n    img = cv2.resize(img ,(im_height, im_width))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test_b['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-30T17:57:52.525140Z","iopub.execute_input":"2022-09-30T17:57:52.526016Z","iopub.status.idle":"2022-09-30T17:58:07.368905Z","shell.execute_reply.started":"2022-09-30T17:57:52.525980Z","shell.execute_reply":"2022-09-30T17:58:07.367992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test_b.index))\n    print(index)\n    img = cv2.imread(df_test_b['filename'].iloc[index])\n    img = cv2.resize(img ,(im_height, im_width))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test_b['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T12:19:08.946827Z","iopub.execute_input":"2022-09-29T12:19:08.947198Z","iopub.status.idle":"2022-09-29T12:19:23.212086Z","shell.execute_reply.started":"2022-09-29T12:19:08.947166Z","shell.execute_reply":"2022-09-29T12:19:23.211147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test_b.index))\n    print(index)\n    img = cv2.imread(df_test_b['filename'].iloc[index])\n    img = cv2.resize(img ,(im_height, im_width))\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test_b['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T12:19:32.651781Z","iopub.execute_input":"2022-09-29T12:19:32.652136Z","iopub.status.idle":"2022-09-29T12:19:46.674258Z","shell.execute_reply.started":"2022-09-29T12:19:32.652105Z","shell.execute_reply":"2022-09-29T12:19:46.673265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}